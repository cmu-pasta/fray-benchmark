{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fray_benchmark.visualizer.bench_result import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kick The Tire\n",
    "\n",
    "In this section, you will visualize the SCTBench results using different techniques, each running for one minute and one iteration. The results should resemble Figure 5(a) when the x-axis shows values less than one minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = BenchmarkSuite([\"../../output/kickthetire/sctbench\"])\n",
    "ax = suite.generate_bug_over_time_fig(\"time\")\n",
    "fig = ax.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ 1 Bug-finding effectiveness\n",
    "\n",
    "In this section, you will visualize the SCTBench, JaConTeBe results using different techniques, each running for 10 minute and one iteration. The results should resemble Figure 5(a) and 5(b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5(a)\n",
    "\n",
    "suite = BenchmarkSuite([\"../../output/benchmark/sctbench\"])\n",
    "ax = suite.generate_bug_over_time_fig(\"time\")\n",
    "fig = ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5(b)\n",
    "\n",
    "suite = BenchmarkSuite([\"../../output/benchmark/jacontebe\"])\n",
    "ax = suite.generate_bug_over_time_fig(\"time\")\n",
    "fig = ax.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ 2: Run-time Performance\n",
    "\n",
    "In this section, you will visualize the run-time performance running the SCTBench, JaConTeBe using different techniques, each running for 10 minute and one iteration. The results should resemble Figure 6 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6\n",
    "\n",
    "suite = BenchmarkSuite([\n",
    "    \"../../output/benchmark/jacontebe\",\n",
    "    \"../../output/benchmark/sctbench\"\n",
    "    ])\n",
    "ax = suite.generate_search_space_table()\n",
    "fig = ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7\n",
    "\n",
    "ax = suite.generate_exec_speed_table()\n",
    "fig = ax.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ 3: Applicability to Real-World Software\n",
    "\n",
    "This section evaluates Fray's bug-finding effectiveness on three real-world applications: Lucene, Kafka, and Guava. Running with the `pos` option displays the number of bugs detected in each application using Fray's POS algorithm.\n",
    "\n",
    "**Results Interpretation:**\n",
    "- **Test Run**: Number of tests executed successfully. When running partial evaluations (pos-only), this matches the test count shown in the **Real-world Bugs and Corresponding Run ID** section.\n",
    "- **Failure**: Number of tests that failed, indicating a bug was detected.\n",
    "- **Time**: Number of failures related to timing operations (thread.sleep, wait, etc.).\n",
    "\n",
    "\n",
    "Note that you may find more or fewer bugs depending on the CPU and memory resources you have. However, the results should be similar (within Â±1) to those shown in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lucene\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "suite = BenchmarkSuite([\n",
    "    \"../../output/realworld/lucene\",\n",
    "    ])\n",
    "suite.generate_bug_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guava\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "suite = BenchmarkSuite([\n",
    "    \"../../output/realworld/guava\",\n",
    "    ])\n",
    "suite.generate_bug_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "suite = BenchmarkSuite([\n",
    "    \"../../output/realworld/kafka\",\n",
    "    ])\n",
    "suite.generate_bug_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ 4:  Linearizability of Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "suite = BenchmarkSuite([\n",
    "    \"../../output/realworld/lincheck\",\n",
    "    ])\n",
    "suite.generate_bug_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
